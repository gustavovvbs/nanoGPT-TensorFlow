{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\gugu1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\gugu1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\gugu1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('data.txt', 'r', encoding = 'utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "65\n",
      "1115393\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "vocab_size = len(vocab)\n",
    "n_tokens = len(text)\n",
    "\n",
    "print(vocab)\n",
    "print(vocab_size)\n",
    "print(n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec_layer = tf.keras.layers.TextVectorization(max_tokens = vocab_size)\n",
    "text_vec_layer.adapt(text)\n",
    "encoded_text = text_vec_layer([text])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(len(text_vec_layer.get_vocabulary())*0.9)\n",
    "raw_train_set = encoded_text[:n]\n",
    "raw_test_set = encoded_text[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(sequence, length, shuffle = False, seed = None, batch_size = 32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    ds = ds.window(length + 1, shift = 1, drop_remainder = True)\n",
    "    ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(100000, seed = seed)\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = to_dataset(raw_train_set, shuffle = True, length = 8)\n",
    "test_set = to_dataset(raw_test_set, length = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when inputs are: [[ 1  1  1  1  1  1 27  3]\n",
      " [ 1  1 16  1 34  1  1  1]\n",
      " [ 1  1  1 16  1 34  1  1]\n",
      " [ 4  1 34  1  1  1  1  1]\n",
      " [36  1 36  1  1  1  1  1]]\n",
      "outputs are:[[ 1  1  1  1  1 27  3 56]\n",
      " [ 1 16  1 34  1  1  1  1]\n",
      " [ 1  1 16  1 34  1  1  1]\n",
      " [ 1 34  1  1  1  1  1  7]\n",
      " [ 1 36  1  1  1  1  1  1]]\n"
     ]
    }
   ],
   "source": [
    "listset =list(train_set)\n",
    "print(f'when inputs are: {listset[0][0][:5]}')\n",
    "print(f'outputs are:{listset[0][1][:5]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "\n",
    "class AttentionHead(tf.keras.Model):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.head_size = head_size \n",
    "        self.key = tf.keras.layers.Dense(head_size, use_bias = False)\n",
    "        self.query = tf.keras.layers.Dense(head_size, use_bias = False)\n",
    "        self.value = tf.keras.layers.Dense(head_size, use_bias = False)\n",
    "    \n",
    "    def call(self, x):\n",
    "        #pega as dimensoes de batch, context size e channels do input \n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        v = self.value(x)\n",
    "\n",
    "        trig = tf.linalg.band_part(tf.ones(shape = (T, T)), -1, 0)\n",
    "\n",
    "        att_w = q @ tf.transpose(k, perm = [0, 2, 1]) *(k.shape[-1])**-0.5\n",
    "\n",
    "        att_w = tf.where(trig == 0, -np.inf, att_w)\n",
    "\n",
    "        att_w = tf.nn.softmax(att_w, axis = -1)\n",
    "        \n",
    "        output = att_w @ v\n",
    "\n",
    "        return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.13514826  0.5280335   1.0186923  ...  0.67153645  0.933869\n",
      "   -1.2463728 ]\n",
      "  [ 0.1171567   0.47883236  0.77883315 ...  0.49982318  0.9062302\n",
      "   -0.93722457]\n",
      "  [-0.00403237  0.44227654  0.5928966  ...  0.08205067  1.0044994\n",
      "   -0.2859735 ]\n",
      "  ...\n",
      "  [ 0.06681177  0.40070373  0.73292655 ...  0.19567572  0.95475346\n",
      "   -0.45742366]\n",
      "  [ 0.1275706  -0.18033773 -0.00486103 ... -0.3911594   0.48348394\n",
      "    0.7040245 ]\n",
      "  [-0.22160497  0.0620264   0.32561854 ... -0.05123576  0.5626712\n",
      "   -0.18593575]]\n",
      "\n",
      " [[-1.3091807   0.8946485  -0.12172471 ...  0.25949866  0.39186454\n",
      "   -0.94198704]\n",
      "  [-1.271266    0.8004763  -0.11725113 ...  0.27440572  0.2922587\n",
      "   -0.8750748 ]\n",
      "  [-0.92463726  0.5260108  -0.35492134 ...  0.38115436 -0.16877648\n",
      "   -0.7854398 ]\n",
      "  ...\n",
      "  [-0.45744753  0.6127905   0.00923503 ...  0.3896348   0.02467614\n",
      "   -0.31110883]\n",
      "  [-0.06563734  0.2646031   0.23518266 ...  0.3600964  -0.15568148\n",
      "   -0.24452543]\n",
      "  [-0.2250154   0.5003611   0.0759698  ...  0.54129404 -0.2274189\n",
      "   -0.3938735 ]]\n",
      "\n",
      " [[ 0.19184533  1.946298    1.3584166  ...  2.2660053   0.7159705\n",
      "   -2.5819845 ]\n",
      "  [ 0.42231187  1.0135442   1.3889008  ...  1.8323045   0.07919219\n",
      "   -2.2178135 ]\n",
      "  [ 0.59514356  0.49632305  1.3403761  ...  1.50333    -0.23266262\n",
      "   -1.5596995 ]\n",
      "  ...\n",
      "  [ 0.04314077  0.82856894  0.9546989  ...  1.0060487   0.21880417\n",
      "   -1.2544321 ]\n",
      "  [-0.73377573  1.0655022   0.23845004 ... -0.27607378  1.8401222\n",
      "   -0.3664348 ]\n",
      "  [ 0.5942496   0.70694745  1.161577   ...  1.3114376  -0.04067811\n",
      "   -1.7693839 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.4166268  -0.5527001   1.1830401  ... -0.34222332  0.33318833\n",
      "    0.587707  ]\n",
      "  [ 0.46136305 -0.49339917  1.1821936  ... -0.09759121  0.2492087\n",
      "    0.3962018 ]\n",
      "  [ 0.68355536 -0.4340413   0.9773738  ...  0.13589856  0.07778698\n",
      "    0.13126463]\n",
      "  ...\n",
      "  [ 0.5121414  -0.37840572  0.75231797 ...  0.11962138  0.12034024\n",
      "    0.28984246]\n",
      "  [ 0.8406016  -0.30218717  0.7133794  ...  1.0361214  -0.16751152\n",
      "   -0.31662378]\n",
      "  [ 0.8108037   0.02245133  0.2927034  ...  0.92241126 -0.14974049\n",
      "   -0.31764582]]\n",
      "\n",
      " [[-1.1308758  -0.08714414  0.14685833 ...  0.37426966 -1.813572\n",
      "    1.0229735 ]\n",
      "  [-0.86046314  0.11632273 -0.18576032 ...  0.4318823  -1.440292\n",
      "    0.41133472]\n",
      "  [-0.67267054  0.2098506   0.00742301 ...  0.45930174 -0.91806966\n",
      "    0.20583743]\n",
      "  ...\n",
      "  [-0.08068275  0.33953112  0.10200465 ...  0.46640557  0.17471996\n",
      "   -0.3595518 ]\n",
      "  [ 0.13045439  0.09164827 -0.40115085 ...  0.46243638 -0.29586324\n",
      "   -0.44460154]\n",
      "  [-0.12506807 -0.29959497  0.012595   ... -0.41804487  0.2440884\n",
      "    0.29289836]]\n",
      "\n",
      " [[-0.45238483  0.00359666  0.08804226 ... -0.80846334 -0.1828289\n",
      "    0.59775555]\n",
      "  [-0.07392617  0.07053839  0.8185768  ...  0.317741   -0.5191826\n",
      "   -0.04996008]\n",
      "  [ 0.2813701  -0.11357248  0.9737361  ...  0.4587742  -0.32177365\n",
      "    0.20481566]\n",
      "  ...\n",
      "  [-0.27357092  0.53690046  0.1822291  ...  0.37232316  0.48764986\n",
      "   -0.43173337]\n",
      "  [-0.02988627  0.04140005  0.25855714 ... -0.2298423   0.32540882\n",
      "    0.38195306]\n",
      "  [-0.04541926 -0.34777296 -0.85969913 ... -0.671249   -1.2326554\n",
      "    0.36051247]]], shape=(16, 8, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "head = AttentionHead(head_size = 8)\n",
    "ex = head(tf.random.normal(shape = (16, 8, 8)))\n",
    "print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.Model):\n",
    "    def __init__(self, head_size, n_heads):\n",
    "        super().__init__()\n",
    "        self.heads = [AttentionHead(head_size) for _ in range(n_heads)]\n",
    "        self.proj = tf.keras.layers.Dense(512)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.concat([head(x) for head in self.heads], axis = -1)\n",
    "        output = self.dropout(self.proj(x))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.3321398  -0.7190646   0.44245768 ...  0.6223686  -0.7113696\n",
      "   -0.4741667 ]\n",
      "  [-0.1328101   0.01300516  0.7941319  ...  0.9208839  -0.5404895\n",
      "   -0.68974406]\n",
      "  [ 0.00597587 -0.1459011   0.18166949 ...  0.6642619  -0.32959124\n",
      "   -0.25672665]\n",
      "  ...\n",
      "  [ 0.06108956 -0.00591415  0.4675648  ...  0.47480628 -0.32441822\n",
      "    0.00615877]\n",
      "  [ 0.17922564 -0.4010697  -0.33308727 ...  0.524374   -0.41959387\n",
      "    0.20542389]\n",
      "  [ 0.42776018  0.35657212 -0.06330115 ... -0.06528842 -0.24698775\n",
      "    0.25748938]]\n",
      "\n",
      " [[-0.05145645  0.03447387  0.24125472 ...  0.03352184  0.06232354\n",
      "    0.10742572]\n",
      "  [ 0.31906065 -0.03229548  0.13656142 ...  0.59888995 -0.35774288\n",
      "    0.1417208 ]\n",
      "  [ 0.38997525  0.18811803  0.31733143 ...  0.47334248 -0.09240919\n",
      "    0.10710604]\n",
      "  ...\n",
      "  [ 0.20792331  0.11270777  0.1132971  ... -0.06615053  0.1600423\n",
      "    0.05115881]\n",
      "  [ 0.05968008  0.03865811 -0.0465684  ...  0.21260321  0.26763475\n",
      "    0.14714469]\n",
      "  [-0.2507594  -0.08851967  0.10379519 ...  0.06685927 -0.29491842\n",
      "    0.47746113]]\n",
      "\n",
      " [[ 0.09709855 -0.41089353 -0.05003949 ... -0.51745325  0.14768486\n",
      "   -0.84207803]\n",
      "  [-0.17184007  0.11041352 -0.54749525 ... -0.09982383 -0.20877671\n",
      "   -0.56007516]\n",
      "  [ 0.24320084  0.07190338 -0.2674283  ... -0.25412348  0.0538602\n",
      "    0.38916448]\n",
      "  ...\n",
      "  [ 0.10153215 -0.08378649 -0.23667891 ... -0.1372752  -0.03162265\n",
      "   -0.0172061 ]\n",
      "  [-0.10185684  0.22963916  0.04331674 ... -0.20378983  0.54025966\n",
      "   -0.2523949 ]\n",
      "  [ 0.07755858  0.40227622  0.02451606 ... -0.14131667  0.34270182\n",
      "   -0.0478426 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.10781847  0.36059433 -1.0974672  ... -0.49762404  0.21638972\n",
      "   -0.02008504]\n",
      "  [ 0.17386226 -0.00847805 -0.2074234  ... -0.24442792  0.1841289\n",
      "    0.03829734]\n",
      "  [-0.31343964  0.02050303 -0.48534527 ... -0.31475073 -0.12418074\n",
      "    0.04454099]\n",
      "  ...\n",
      "  [-0.8372912   0.16421847 -0.8513192  ... -0.46432382  0.10118283\n",
      "   -0.46426174]\n",
      "  [-0.10085621 -0.24333127 -0.51803964 ... -0.16484027 -0.05944184\n",
      "    0.09741335]\n",
      "  [-0.44348696 -0.06446601 -0.49896726 ... -0.19643727 -0.18546583\n",
      "   -0.01680576]]\n",
      "\n",
      " [[ 0.33341295 -0.19194637  0.613064   ...  0.83204263 -0.09799953\n",
      "    0.02528344]\n",
      "  [ 0.37494075 -0.24163766  0.59523225 ...  0.691177   -0.3789675\n",
      "   -0.16965899]\n",
      "  [ 0.30330393  0.09945547  0.18855233 ...  0.43358025 -0.09706253\n",
      "    0.18412429]\n",
      "  ...\n",
      "  [ 0.09430384  0.03716652 -0.37486726 ...  0.04673054 -0.3357831\n",
      "    0.07756921]\n",
      "  [-0.09235448  0.24376051  0.43153307 ... -0.09820398  0.20987304\n",
      "   -0.54880553]\n",
      "  [ 0.42771316 -0.23356165  0.34280074 ... -0.01198747  0.06548894\n",
      "   -0.06332592]]\n",
      "\n",
      " [[-0.07872404  0.01836115  0.8655386  ...  0.8796661  -0.5170154\n",
      "    0.2782691 ]\n",
      "  [ 0.45874393 -0.28277236 -0.14655672 ...  0.91237426 -0.42382354\n",
      "    0.56295025]\n",
      "  [ 0.3498543  -0.16550608  0.41045588 ...  0.6684222  -0.64595306\n",
      "   -0.05634424]\n",
      "  ...\n",
      "  [ 0.22447886  0.00772934 -0.09273467 ...  0.299448   -0.30486035\n",
      "    0.46206838]\n",
      "  [ 0.12822674  0.75839454 -0.38852602 ...  0.62457305  0.47281277\n",
      "    0.01403702]\n",
      "  [ 0.18305959 -0.051973    0.37955472 ...  0.44225127 -0.1362677\n",
      "    0.14997423]]], shape=(16, 8, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mha = MultiHeadAttention(8, 8)\n",
    "rt = mha(tf.random.normal(shape = (16, 8, 8)))\n",
    "print(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyC(tf.keras.Model):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.dense = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(n_embed*4),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Dense(n_embed),\n",
    "            tf.keras.layers.Dropout(0.2)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        output = self.dense(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(tf.keras.Model):\n",
    "    def __init__(self, n_head, n_embed):\n",
    "        super().__init__()\n",
    "        self.head_size = n_embed // n_head\n",
    "        self.attention = MultiHeadAttention(self.head_size, n_head)\n",
    "        self.fc = FullyC(n_embed)\n",
    "        self.lnorm1 = tf.keras.layers.LayerNormalization()\n",
    "        self.lnorm2 = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        #comunicacao entre os tokens\n",
    "        x = x + self.attention(self.lnorm1(x))\n",
    "        #aplicar o resultado da comunicacao\n",
    "        x = x + self.fc(self.lnorm2(x))\n",
    "\n",
    "        return x    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1.1816843e+00 -1.4835200e+00  6.3604303e-02 ...  3.0810449e+00\n",
      "   -9.4437355e-01 -1.7423807e+00]\n",
      "  [ 5.2200246e-01  1.0362380e+00  7.2791767e-01 ...  3.5537279e+00\n",
      "   -1.7957218e+00 -2.7891750e+00]\n",
      "  [ 8.0691642e-01  9.2628825e-01  1.5238235e+00 ... -1.4639750e+00\n",
      "   -2.4314165e+00 -1.3000362e+00]\n",
      "  ...\n",
      "  [-5.9576136e-01  8.4466469e-01 -1.0049163e-01 ...  1.2310945e+00\n",
      "   -6.9342732e-01  2.8673787e+00]\n",
      "  [-1.2807531e+00 -4.6848702e-01  8.2960701e-01 ... -4.9219424e-01\n",
      "   -2.3903012e-02  3.7137562e-01]\n",
      "  [-1.8777981e-01  3.6788848e-01  5.1506132e-01 ...  4.7023594e-01\n",
      "   -8.2354534e-01  1.4433665e+00]]\n",
      "\n",
      " [[ 1.2584934e+00  2.0127578e+00  2.7901628e+00 ... -2.6109023e+00\n",
      "   -1.0930128e+00  6.5043902e-01]\n",
      "  [-1.2569017e+00 -1.0176800e+00 -9.5043164e-01 ...  4.0001094e-01\n",
      "   -2.7922771e+00  7.3407853e-01]\n",
      "  [ 2.4482346e+00 -1.9173974e+00  1.2827530e+00 ...  1.6615255e+00\n",
      "   -1.6776222e+00  1.7422601e+00]\n",
      "  ...\n",
      "  [ 3.8630038e-02  6.6993678e-01  1.0081298e+00 ... -8.1283808e-01\n",
      "   -1.9896808e+00  1.3170512e+00]\n",
      "  [ 9.9158227e-01  9.3383157e-01  3.7956476e-01 ... -3.0791664e+00\n",
      "    1.4038274e-01  4.7992659e-01]\n",
      "  [ 8.4688532e-01 -5.8928502e-01  1.3006921e+00 ... -1.9051206e-01\n",
      "   -1.8587366e+00 -9.0957236e-01]]\n",
      "\n",
      " [[-4.3260163e-01  3.0042107e+00 -2.9292889e+00 ...  4.2209303e-01\n",
      "   -1.4485233e+00  1.2840331e+00]\n",
      "  [ 2.5819173e-01  1.8783785e+00 -1.0874826e-01 ... -1.1619434e-01\n",
      "   -1.8085927e+00  1.8674561e+00]\n",
      "  [-7.1660161e-01  3.2037768e+00 -2.7103975e-02 ...  2.8908503e+00\n",
      "   -2.0529244e+00 -5.6132716e-01]\n",
      "  ...\n",
      "  [-1.8406121e+00  1.4915146e+00 -1.6526740e+00 ... -1.4251217e+00\n",
      "    6.4251739e-01 -1.6068991e+00]\n",
      "  [ 5.0134516e-01  1.1903739e+00  3.8753519e+00 ... -1.4594203e+00\n",
      "    5.0788510e-01 -1.3846755e+00]\n",
      "  [-1.8986355e+00 -5.3009200e-01 -1.4604895e+00 ... -7.7176988e-02\n",
      "   -1.3614302e+00  1.2955868e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3.3944410e-01  1.0828712e+00 -7.4868739e-01 ...  9.8464078e-01\n",
      "    7.5389421e-01 -1.2472441e+00]\n",
      "  [-2.6151924e+00  1.0134571e+00 -9.4324201e-01 ... -2.9787669e+00\n",
      "   -1.5497704e+00 -9.4400251e-01]\n",
      "  [-1.4987636e-01 -4.3335408e-01 -3.5790415e+00 ... -8.0246383e-01\n",
      "   -4.6979630e-01  2.2581375e+00]\n",
      "  ...\n",
      "  [ 6.3187122e-01 -2.0098677e+00 -1.6474837e+00 ... -1.6469147e+00\n",
      "    3.5215059e-01 -2.1536691e+00]\n",
      "  [-1.7126710e+00 -2.8348045e+00 -4.0764815e-01 ... -2.8537780e-01\n",
      "   -4.7567081e-01 -8.3637440e-01]\n",
      "  [-8.6314100e-01 -1.5992059e+00  1.0241179e+00 ...  6.4402026e-01\n",
      "   -1.1248338e-01  2.6785057e+00]]\n",
      "\n",
      " [[-1.7120855e+00 -3.1604618e-01 -3.6670488e-01 ...  7.3817885e-01\n",
      "    1.3577353e+00  9.2446959e-01]\n",
      "  [-5.7559597e-01  3.9255676e-01  5.9074593e-01 ...  2.0214558e-01\n",
      "   -9.0003276e-01 -8.6564481e-01]\n",
      "  [-8.6483061e-03  1.1974609e-01 -2.0777454e+00 ... -2.2099192e+00\n",
      "   -1.1055726e+00 -2.0329986e+00]\n",
      "  ...\n",
      "  [-2.2912533e+00 -3.8260013e-02 -8.2125300e-01 ...  1.1454482e+00\n",
      "   -1.8724651e+00 -1.5343962e+00]\n",
      "  [ 7.3419881e-01  5.2001345e-01  3.3349898e-01 ... -1.1577392e+00\n",
      "    7.0488191e-01 -6.2029207e-01]\n",
      "  [ 3.3551854e-01 -7.7790588e-01  7.0821255e-01 ...  1.3850713e-01\n",
      "   -2.0706425e+00 -2.3274674e+00]]\n",
      "\n",
      " [[ 5.6097406e-01 -3.9801002e-04 -2.0335336e+00 ...  2.9924662e+00\n",
      "   -2.1060927e+00 -1.1991761e+00]\n",
      "  [ 9.9130613e-01 -6.4655674e-01 -2.1812081e-02 ...  2.5792136e+00\n",
      "   -4.7630653e+00 -1.9823213e+00]\n",
      "  [-9.5061862e-01  1.8512137e+00 -5.6845605e-02 ... -2.1324840e+00\n",
      "    1.9403100e-02 -2.3183119e+00]\n",
      "  ...\n",
      "  [ 3.3142397e+00  4.4742104e-01 -6.0579801e-01 ...  3.3327227e+00\n",
      "   -1.6729988e+00 -1.2588527e+00]\n",
      "  [-4.3296361e-01  3.0553505e-01  2.1410465e+00 ... -6.3057077e-01\n",
      "    9.9494457e-01  1.9947559e-01]\n",
      "  [-8.0461943e-01 -6.9693089e-01 -2.9491854e-01 ... -1.1249123e+00\n",
      "   -9.1720939e-01 -1.8600396e+00]]], shape=(16, 32, 512), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gugu1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\layer.py:372: UserWarning: `build()` was called on layer 'block_4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "block = Block(16, 512)\n",
    "ajs = block(tf.random.normal(shape=(16, 32, 512)))\n",
    "print(ajs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
